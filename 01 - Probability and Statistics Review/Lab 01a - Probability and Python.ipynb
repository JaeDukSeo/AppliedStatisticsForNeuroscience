{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/HWNI_logo.svg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01a - Review of Probability and Python Fundamentals\n",
    "\n",
    "We'll begin by going over both key notions from probability and some of the most fundamental statistics -- means, medians, and so on. We'll also take this opportunity to practice using the technological tools we'll need for this course.\n",
    "\n",
    "In this first (shorter) half of the lab, we'll be reviewing probability and using some of the fundamental tools of Python: lists, dictionaries, and functions.\n",
    "\n",
    "If you've never done any computer programming before, make sure to work through the [Codecademy Python course](https://www.codecademy.com/learn/python) through Lesson 9 as soon as possible. You won't necessarily need it to make it through this lab, but baseline comfort with programming is a key skill for this course and for most of science today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# makes our plots show up inside Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# seaborn - easy plotting for statistical visualizations\n",
    "#   based off of matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "import util.lab01utils as utils \n",
    "\n",
    "# choose colors that work for most color-blind folks\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning of a statement like \"the chance that I roll a die and it comes up 6 is 1/6\" is both intuitively obvious and flabbergastingly difficult to pin down. Indeed, the foundations of probability are a topic for [philosophy](https://plato.stanford.edu/entries/probability-interpret/) as much as or more than for mathematics. Four alternative interpretations of that statement appear below: \n",
    "\n",
    "- If I were to prepare a large number of dice identical to this one and roll them all at once, about 1/6 of them would come up 6\n",
    "- If I were to examine all possible universes consistent with my beliefs right now, then 1/6 of them contain me rolling a die that comes up as a 6\n",
    "- If I wish to think logically about the statement \"the die comes up a 6\", I should assign the truth value 1/6, given my current beliefs\n",
    "- The mathematical rules that I need to apply to games involving rolling dice in order to avoid being cheated tell me to assign the number 1/6 to the event \"the die comes up a 6\"\n",
    "\n",
    "Which of these interpretations you prefer is, in the end, an aesthetic choice. The lattermost view, due to [de Finetti](https://en.wikipedia.org/wiki/Bruno_de_Finetti), is known as the [\"Dutch Book\"](https://en.wikipedia.org/wiki/Dutch_book) argument and is popular among financial mathematicians and stock traders. The formermost view, the [*frequentist* view](https://en.wikipedia.org/wiki/Frequentist_probability), is most popular among practicing scientists and is the \"traditional\" view among statisticians. The second and third views are two flavors of [*Bayesianism*](http://charlesfrye.github.io/stats/2016/02/04/bayes-rule.html), and are popular among cognitive and computer scientists and the current generation of statisticians. The third is forcefully argued for by [Edwin Jaynes](https://en.wikipedia.org/wiki/Edwin_Thompson_Jaynes) in his posthumous work *Probability Theory: The Logic of Science*.\n",
    "\n",
    "We won't dwell on these questions here, but it's worth considering what your opinion is and why you hold it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Probability Distributions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of what it \"really means\", once we have a notion of probability, we can start using math to model it and understand it better. Armed with a few common sense ideas -- the probability that \"something happens\" is always 1, nothing can have a negative probability, and the probability of either of two things happening is at least as much as one of them happening -- we can define two important notions: the *probability mass function* and the *probability density function*. These are both examples of *probability distributions*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Mass Functions\n",
    "\n",
    "If I roll a die, only one of 6 things might happen -- I'll get a number from 1 to 6. If the die is well-made and fair, each number will have the same chance of showing up. If the die is poorly-made, there will be some small variations, and if the die is unfair, there will be some big variations.\n",
    "\n",
    "We'd like to be able to describe the differences between these dice with numbers. We do this by defining, for each die, a function that takes in a number between 1 and 6 and spits out the probability that rolling the die will result in that number. We call this the *probability mass function*.\n",
    "\n",
    "Why *mass function*? Remember two of our common sense ideas about probability: nothing can have a negative probability, and the probability of either of two things happening is at least as much as one of them happening. These are the same restrictions that we have when we're talking about the masses of objects: nothing can have a negative mass, and the mass of two things is at least as much as the mass of one of the things (remember the case where the two things overlap). Mathematically, probabilities are like masses that sum up to one -- we put a lot of weight on events that are likely to occur and less weight on events that are unlikely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Mass Functions in Python\n",
    "\n",
    "Here are two good ways to represent probability mass functions in Python: as *lists* and as *dictionaries*. Lists are good when the probability mass functions take in numbers, as in our dice-rolling example, while dictionaries are good when the probability mass functions take in something else, like the suit and rank of a playing card. We could also use *functions*, which are discussed more below.\n",
    "\n",
    "#### Probability Mass Functions with Lists\n",
    "\n",
    "A list is an ordered collection of objects -- everything in Python is an object, so a list can contain numbers, strings, even functions or other lists! Because lists are ordered, we can retrieve items from a list using a number -- the *index*, or how far into the list the item is. Note that the \"first\" item in a list is, in Python, at index `0`.\n",
    "\n",
    "To represent a probability mass function, we want a *list of numbers*. Below, I've written out the probability mass function for a fair die. Underneath it, please write the probability mass function (PMF for short) for an unfair die of your choosing. The code in the cell after next will plot both mass functions, so you can see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list = [item0,item1,item2, ... ]\n",
    "\n",
    "fairPMF = [0,1/6,1/6,1/6,1/6,1/6,1/6,0]\n",
    "\n",
    "unfairPMF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils.plotPMF(fairPMF,title='PMF for a Fair Die');\n",
    "utils.plotPMF(unfairPMF,title='PMF for an Unfair Die');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is the first element of the list 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, calculate the chance of each of the following events for the fair and unfair die.\n",
    "\n",
    "a. 6\n",
    "  \n",
    "b. Greater than 3\n",
    "  \n",
    "c. Either odd or less than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability Mass Functions with Dictionaries\n",
    "\n",
    "Now, we ran into a bit of awkwardness up there when we defined our probability mass function because Python list indices start at 0 but dice start at 1. If dice started at 100, we would've been in real trouble! And if we'd been working with playing cards instead of dice, we wouldn't have had any way to proceed.\n",
    "\n",
    "One way out would be to declare that `fairPMF[0]` is the probability that 1 comes up, rather than 0, and so on up until `fairPMF[5]`, the probability that 6 comes up. This is a perfectly acceptable solution, but it requires you to remember that `1` the index is not 1, the number on the die. That's OK in this case, but when you try and extend it to something more complicated, like the deck of cards, the relationship between index and outcome can get hairy.\n",
    "\n",
    "We can avoid this using *dictionaries*, which are like lists that use names as indices, instead of numbers. These names are called *keys*. Like paper dictionaries, when I want to look up an object in a Python dictionary, I use its name. Unlike paper dictionaries, the contents are not sorted, and unlike lists, their order might change.\n",
    "\n",
    "Below, I've defined two probability mass functions with dictionaries, one for a fair die and the other for the grade distribution of a curved class (not this one!). Define your own to make sure you've got the hang of the syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary = {key0:item0, key1:item1, ... }\n",
    "\n",
    "fairPMF = {1:1/6,\n",
    "           2:1/6,\n",
    "           3:1/6,\n",
    "           4:1/6,\n",
    "           5:1/6,\n",
    "           6:1/6,\n",
    "          }\n",
    "\n",
    "gradesPMF = {'A':0.25,'B':0.4,'C':0.2,'D':0.05,'F':0.1}\n",
    "\n",
    "#yourPMF goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, calculate the following:\n",
    "\n",
    "a. the chance a fair die comes up even\n",
    "\n",
    "b. the chance a randomly-chosen student passes the class (D or higher)\n",
    "\n",
    "c. the chance of an interesting event based on your PMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Density Functions\n",
    "\n",
    "Probability mass functions are useful, but there are some situations where they're not enough. For example, say I throw a dart at a circular dartboard and ask where it landed. There are so many possible places that the dart could land that it's impossible to list them all, even with infinite time (this is called an *uncountable infinity*). We need to be able to list something in order to define a probability mass function, so we need something new to handle these cases.\n",
    "\n",
    "We introduce the *probability density function* by analogy to the densities we encounter in the physical world. The density function of an object tells you how its mass is distributed -- where there is more mass per unit volume, the density is higher, and where there is less, the density is lower. We can use density functions to calculate how much mass there is in every part of an object.\n",
    "\n",
    "When the density is the same across the whole object, we can just multiply this constant density value by the volume of the part we're interested in to get the mass. For complicated objects, like humans and laptop computers, the density will be very different at different points. If we want to know how much an object weighs, we need to take a whole bunch of small volumes and add up how much mass is in each of them. The smaller the volumes we take, the more accurate our measurement of the mass will be -- the density can't change too much if the volume is small. Using calculus, we can describe mathematically what happens when our volumes are \"infinitely small\" and so the mass we calculate will be exactly correct. You may be familiar with this idea, which is called an *integral*.\n",
    "\n",
    "So, just like the density function is the function we integrate in order to get the mass of any part of an object, a probability density function is the function we integrate in order to get the probability of any group of events out of the possible outcomes. Again, we want the chance that \"something happens\" to be 1, so we say that the integral of a probability density function is 1. \n",
    "\n",
    "When we want to speak generally about a collection of probabilities but don't want to specify whether it's a mass function or a density function, we call it a *probability distribution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability Density Functions in Python\n",
    "\n",
    "Because we cannot list all of the possible outcomes, we cannot use a list or a dictionary to represent a probability density function. Instead, we need to use a Python *function*. Just like a mathematical function, a Python function takes in an input and returns an output. Python functions can be used to represent mass or density functions.\n",
    "\n",
    "Below, I've defined a Python function that corresponds to a probability density function that is equal to 1 between 0 and 1 and 0 everywhere else. A probability density or mass function that is equal to some constant value for certain numbers and 0 for all others is called a *uniform* density or mass function.\n",
    "\n",
    "Write your own probability density function below. For simplicity's sake, let's say that only outcomes between 0 and 1 are possible, just like in my `uniformPDF`. That means `yourPDF` can be any function that integrates to one between 0 and 1. Remember: the integral is equal to the \"area under the curve\". What are some shapes you know the area of?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def function(input0,input1,...):\n",
    "    # do stuff\n",
    "    # to inputs\n",
    "    # make outputs\n",
    "    # return outputs\n",
    "\n",
    "def uniformPDF(x):\n",
    "    if 0 < x < 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def yourPDF(x):\n",
    "    if 0 < x < 1:\n",
    "        pass # your code here\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "utils.plotPDF(uniformPDF,title='Uniform PDF')\n",
    "\n",
    "utils.plotPDF(yourPDF,title='Your PDF')\n",
    "\n",
    "assert utils.integratesToOne(yourPDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the maximum value of your probability density function? Was it greater than 1? What about for your probability mass function? Why is an output bigger than 1 possible in one case but not the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Density Functions\n",
    "\n",
    "Instead of asking \"what's the probability density at x?\", it's sometimes more natural to ask \"what's the probability that the value is less than or equal to x?\". For every x, the result is a value that is between 0 and 1 (why?). Since we can put in any x and get out a single answer, we have defined a function! The function that takes in a number and tells you the probability that a random value is less than or equal to that number is called the *cumulative distribution function*, since it tracks how much probability has \"accumulated\" up to a given number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Probability to Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability comprises a set of mathematical tools and concepts that we can use to model and understand events that occur \"randomly\". In science, the events of interest are observations of physical systems, usually organized into experiments. We collect these observations, also called *data*, into datasets, and then we wish to understand those datasets. *Statistics* is the applied mathematical discipline of understanding datasets using probability.\n",
    "\n",
    "In the next (longer) half of the lab, we'll cover some fundamental ideas of statistics and implement them with the Python libraries pandas, numpy, and seaborn."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:neur299]",
   "language": "python",
   "name": "conda-env-neur299-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
