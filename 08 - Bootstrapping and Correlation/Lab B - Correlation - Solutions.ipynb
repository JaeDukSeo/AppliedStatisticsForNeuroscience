{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/HWNI_logo.svg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab B - Correlation - Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes our plots interactive\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import util.utils as utils\n",
    "import util.shared as shared\n",
    "\n",
    "shared.format_plots()\n",
    "shared.format_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A technical note: like Lab 06, this notebook uses the interactive features of JuPyter notebooks. This means that when you generate a plot, you can keep adding things to that plot, so long as you don't either 1) make a new figure or 2) click the blue \"power button\" in the top-right corner of the figure.\n",
    "\n",
    "To prevent yourself from accidentally plotting into a figure you didn't mean to plot into, make sure to include a `plt.figure()` in each cell where you're making a plot. You'll want to do this right before you do the plotting commands (`sns.distplot`, `plt.plot`,etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class, we discussed several views of what the correlation means.\n",
    "\n",
    "#### Q Which one is your favorite?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"1874CD\"> ** I think of correlation as a quantification of how good the best model is -- it's the square root of the variance explained by the linear model. We pick the positive or negative square root depending on whether the relationship is positive or negtive. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's generate some correlated data.\n",
    "\n",
    "The simplest way to generate data that is dependent is to first sample one set of random numbers, then generate another set whose values depend on the first. \n",
    "\n",
    "In this example, we create correlated data by first sampling an array of x values from a standard normal and then generating an array of ys by adding another set of random numbers to the xs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPoints = 50\n",
    "noise_level = 2\n",
    "\n",
    "def generateData(numPoints,noise_level):\n",
    "    xs = np.random.standard_normal(size=numPoints)\n",
    "    ys = np.asarray([x+np.random.standard_normal()*noise_level\n",
    "                 for x in xs])\n",
    "    \n",
    "    return xs,ys\n",
    "\n",
    "xs,ys = generateData(numPoints,noise_level)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(xs,ys,\n",
    "            s=24,linewidth=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python offers a number of options for computing the correlation coefficient of two or more datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy offers the `corrcoef` function. This function returns a correlation matrix -- the `ij`th entries of this matrix tell you the correlation between the `i`th and `j`th arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q What do you expect the correlation coefficient to be when `i == j` (i.e. for the diagonal elements of the matrix)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"1874CD\"> ** It's 1 -- a variable is perfectly correlated with itself! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `corrcoef` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(xs,ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase the `noise_level` above.\n",
    "\n",
    "#### Q What happens to the  correlation coefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"1874CD\"> ** It goes down. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers a way to calculate the correlation matrix of the numeric columns in a data frame. Data frames have a method, `.corr` that returns the correlation matrix as a data frame.\n",
    "\n",
    "First, we have to get our data into the pandas `DataFrame` format. Do this in the cell below using `pd.DataFrame.from_dict` or `.from_items`, then calculate the correlation matrix using `data.corr()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_items([('x',xs),('y',ys)])\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn's prime directive is to make things that people do frequently as painless as possible. Since plotting pairs of things and calculating their correlation is a very common step in data analysis, seaborn makes it extremely easy.\n",
    "\n",
    "Use the function `sns.jointplot` to simultaneously make a scatter plot of the data, calculate the correlation coefficient, and get a bootstrapped $p$-value for the correlation (it's easier than it sounds!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=df,x='x',y='y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discussed a formula for the correlation coefficient, $r$. It is reproduced below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "r = \\frac{1}{n-1} \\sum_{i=1}^{n}{\\frac{(x_i-\\mu_x)}{s_x}\n",
    "                                  \\frac{(y_i-\\mu_y)}{s_y}}\n",
    "$$\n",
    "\n",
    "where $s_a$ is the estimated population standard deviation of a variable $a$:\n",
    "\n",
    "$$\n",
    "s_a = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n}{\\left(a_i-\\mu_a\\right)^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this formula to define a function that will compute the correlation coefficient of any pair of random variables, then run that function on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlate(xs,ys):\n",
    "    assert len(xs) == len(ys), \"arrays must be same size\"\n",
    "    zScored_xs = zScore(xs)\n",
    "    zScored_ys = zScore(ys)\n",
    "    return np.dot(zScored_xs,zScored_ys)/(len(xs)-1)\n",
    "\n",
    "def zScore(xs):\n",
    "    mu = np.mean(xs)\n",
    "    sd = np.std(xs,ddof=1)\n",
    "    zs = [(x - mu)/sd for x in xs]\n",
    "    return zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlate(xs,ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Confidence Intervals on Correlations with Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first half of the lab, we examined the bootstrapping procedure for estimating the sampling distribution of statistics. Now, we'll use that procedure to estimate the sampling distribution of the correlation coefficient.\n",
    "\n",
    "In the cell below, implement the bootstrap for the correlation coefficient. That is, generate a dataset of size $N$ (aka `numPoints`). Then, draw $N$ pairs of `x` and `y` values from the dataset (with replacement) and calculate the correlation coefficient. You can use `np.random.randint(0,len(data)` to generate a random list of indices for sampling with replacement. Draw pairs from the same dataset at least 1000 times and then plot the distribution of the resulting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numPoints = 50\n",
    "noise_level = 2\n",
    "\n",
    "xs,ys = generateData(numPoints,noise_level)\n",
    "\n",
    "data = np.asarray([xs,ys]).T #this format is more convenient for bootstrapping\n",
    "\n",
    "def bootstrapSample(data):\n",
    "    # draw N pairs of x and y values\n",
    "    indices = np.random.randint(0,len(data),size=len(data))\n",
    "    return data[indices]\n",
    "\n",
    "def runBootstrap(data,numBootstraps):\n",
    "    #use bootstrapSample numBootstraps times,\n",
    "    # computing the correlation coefficient each time\n",
    "    rs = np.zeros(numBootstraps)\n",
    "    for bootstrapIdx in range(numBootstraps):\n",
    "        sample = bootstrapSample(data)\n",
    "        rs[bootstrapIdx] = np.corrcoef(sample.T)[0,1]\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numBootstraps = 10000\n",
    "rs = runBootstrap(data,numBootstraps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correlate(xs,ys))\n",
    "\n",
    "plt.figure()\n",
    "sns.distplot(rs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given (an approximation to) the sampling distribution, we can calculate a confidence interval at confidence level $\\alpha$ by dropping the extreme values of the sampling distribution -- the lower bound of the confidence interval is the $\\alpha/2$th percentile of the sampled values and the upper bound of the confidence interval is the $1-\\alpha/2$th percentile.\n",
    "\n",
    "Compute the confidence interval for your correlation coefficient in the cell below. Use, as we do out of habit, $\\alpha=0.05$. Hint: look up `np.percentile`. Notice that it takes percentiles as values between 0 and 100, not between 0 and 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = correlate(xs,ys)\n",
    "\n",
    "def computeCI(rs,alpha=.05):\n",
    "    CI = [np.percentile(rs,100*alpha/2),\n",
    "          np.percentile(rs,100*(1-alpha/2))]\n",
    "    return CI\n",
    "\n",
    "print(r)\n",
    "computeCI(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can compute a confidence interval, we can compute a p-value.\n",
    "\n",
    "#### Q Briefly, how would you check if a result is significant at a level $\\alpha$ using the set of sampled $r$s?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"1874CD\"> ** Check if the null hypothesis is included in the $1-\\alpha$ confidence interval. **"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
